# Monitoring and Alerting Configuration

# Application Insights
application_insights:
  enabled: true
  sampling_percentage: 100
  instrumentation_key_secret: APP_INSIGHTS_KEY
  
  custom_metrics:
    - name: pipeline_duration
      type: gauge
      unit: seconds
    
    - name: records_processed
      type: counter
      unit: count
    
    - name: data_quality_score
      type: gauge
      unit: percentage

# Azure Monitor
azure_monitor:
  enabled: true
  log_analytics_workspace: log-neo4j-{environment}
  retention_days:
    dev: 30
    staging: 60
    prod: 90
  
  diagnostic_settings:
    - category: AuditLogs
      enabled: true
    - category: AllMetrics
      enabled: true

# Alerts
alerts:
  # Job Failure Alerts
  - name: job_failure
    severity: critical
    condition:
      metric: job_status
      operator: equals
      threshold: failed
      window_minutes: 5
    notification:
      - slack
      - email
      - pagerduty
    environments: [staging, prod]
  
  # Performance Degradation
  - name: slow_pipeline
    severity: warning
    condition:
      metric: pipeline_duration
      operator: greater_than
      threshold: 3600  # 1 hour
      window_minutes: 15
    notification:
      - slack
    environments: [prod]
  
  # Cost Threshold
  - name: high_cost
    severity: warning
    condition:
      metric: daily_cost
      operator: greater_than
      threshold: 200  # USD
      window_hours: 24
    notification:
      - slack
      - email
    environments: [prod]
  
  # Data Quality
  - name: data_quality_low
    severity: warning
    condition:
      metric: data_quality_score
      operator: less_than
      threshold: 95  # percentage
      window_minutes: 30
    notification:
      - slack
    environments: [staging, prod]
  
  # Secret Expiration
  - name: secret_expiring_soon
    severity: warning
    condition:
      metric: secret_days_until_expiry
      operator: less_than
      threshold: 14
      window_hours: 24
    notification:
      - email
    environments: [dev, staging, prod]

# Notification Channels
notification_channels:
  slack:
    enabled: true
    webhook_url_secret: SLACK_WEBHOOK_URL
    channels:
      critical: "#alerts-critical"
      warning: "#alerts-warning"
      info: "#pipeline-status"
  
  email:
    enabled: true
    smtp_server: smtp.gmail.com
    smtp_port: 587
    from_email: noreply@example.com
    recipients:
      critical: ["oncall@example.com", "team-lead@example.com"]
      warning: ["team@example.com"]
      info: ["team@example.com"]
  
  pagerduty:
    enabled: false
    integration_key_secret: PAGERDUTY_INTEGRATION_KEY
    severity_mapping:
      critical: critical
      warning: warning

# Logging
logging:
  level:
    dev: DEBUG
    staging: INFO
    prod: WARNING
  
  format: json
  include_context: true
  
  categories:
    - name: pipeline_execution
      enabled: true
      retention_days: 90
    
    - name: data_quality
      enabled: true
      retention_days: 60
    
    - name: performance
      enabled: true
      retention_days: 30
    
    - name: security_audit
      enabled: true
      retention_days: 365

# Performance Monitoring
performance:
  enable_profiling: true
  sample_rate: 0.1  # 10% of requests
  
  sla_targets:
    pipeline_duration_p95: 3600  # seconds
    pipeline_duration_p99: 5400  # seconds
    success_rate: 99.5  # percentage
  
  track_metrics:
    - cpu_usage
    - memory_usage
    - disk_io
    - network_io
    - spark_metrics

# Dashboard Configuration
dashboards:
  - name: Pipeline Overview
    widgets:
      - type: line_chart
        metric: pipeline_duration
        title: "Pipeline Duration"
      
      - type: counter
        metric: records_processed
        title: "Records Processed"
      
      - type: gauge
        metric: data_quality_score
        title: "Data Quality Score"
      
      - type: status
        metric: last_run_status
        title: "Last Run Status"
  
  - name: Cost Analysis
    widgets:
      - type: line_chart
        metric: daily_cost
        title: "Daily Cost"
      
      - type: pie_chart
        metric: cost_by_service
        title: "Cost by Service"

# Health Checks
health_checks:
  enabled: true
  interval_minutes: 5
  
  checks:
    - name: databricks_workspace
      type: http
      endpoint: "{DATABRICKS_HOST}/api/2.0/clusters/list"
    
    - name: neo4j_connection
      type: tcp
      host: "{NEO4J_HOST}"
      port: 7687
    
    - name: storage_account
      type: azure_storage
      account: "{STORAGE_ACCOUNT_NAME}"
