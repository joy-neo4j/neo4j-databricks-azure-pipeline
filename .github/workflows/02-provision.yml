name: 02 - Provision (Azure + Databricks + Aura + UC)

on:
  workflow_dispatch:

permissions:
  contents: read
  id-token: write

concurrency:
  group: provision-${{ github.ref }}
  cancel-in-progress: true

jobs:
  provision:
    name: Provision single environment via Terraform
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Export ARM environment for Terraform (Service Principal)
        run: |
          set -euo pipefail
          CREDS_JSON='${{ secrets.AZURE_CREDENTIALS }}'
          ARM_CLIENT_ID=$(echo "$CREDS_JSON" | jq -r '.clientId')
          ARM_CLIENT_SECRET=$(echo "$CREDS_JSON" | jq -r '.clientSecret')
          ARM_TENANT_ID=$(echo "$CREDS_JSON" | jq -r '.tenantId')
          ARM_SUBSCRIPTION_ID=$(echo "$CREDS_JSON" | jq -r '.subscriptionId')
      
          echo "ARM_CLIENT_ID=$ARM_CLIENT_ID" >> $GITHUB_ENV
          echo "ARM_CLIENT_SECRET=$ARM_CLIENT_SECRET" >> $GITHUB_ENV
          echo "ARM_TENANT_ID=$ARM_TENANT_ID" >> $GITHUB_ENV
          echo "ARM_SUBSCRIPTION_ID=$ARM_SUBSCRIPTION_ID" >> $GITHUB_ENV

      - name: Prepare Databricks UC (catalog/schemas) and secret scope (idempotent)
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          set -euo pipefail

          # Configuration
          CATALOG_NAME="ecommerce_dev"
          SECRET_SCOPE="pipeline-secrets"

          api() {
            local method="$1" path="$2"; shift 2
            curl -sS -X "$method" "$DATABRICKS_HOST$path" \
              -H "Authorization: Bearer $DATABRICKS_TOKEN" \
              -H "Content-Type: application/json" \
              "$@"
          }

          # Ensure catalog exists
          echo "Checking catalog: $CATALOG_NAME"
          if ! api GET "/api/2.1/unity-catalog/catalogs/$CATALOG_NAME" >/dev/null 2>&1; then
            echo "Creating UC catalog: $CATALOG_NAME"
            api POST "/api/2.1/unity-catalog/catalogs" \
              -d "{\"name\":\"$CATALOG_NAME\",\"comment\":\"E-commerce dev catalog managed by CI\"}"
          else
            echo "Catalog $CATALOG_NAME exists"
          fi

          # Ensure schemas under catalog
          for S in bronze silver gold graph_ready customers products orders analytics; do
            echo "Checking schema: $CATALOG_NAME.$S"
            if ! api GET "/api/2.1/unity-catalog/schemas/$CATALOG_NAME.$S" >/dev/null 2>&1; then
              echo "Creating schema: $S"
              api POST "/api/2.1/unity-catalog/schemas" \
                -d "{\"name\":\"$S\",\"catalog_name\":\"$CATALOG_NAME\"}"
            else
              echo "Schema $S exists"
            fi
          done

          # Ensure databricks secret scope exists
          echo "Checking secret scope: $SECRET_SCOPE"
          # Check if scope exists by listing all scopes and filtering
          SCOPE_LIST=$(api GET "/api/2.0/secrets/scopes/list" 2>/dev/null || echo '{"scopes":[]}')
          SCOPE_EXISTS=$(echo "$SCOPE_LIST" | jq -e --arg s "$SECRET_SCOPE" '.scopes[] | select(.name == $s)' >/dev/null && echo "true" || echo "false")
          
          if [ "$SCOPE_EXISTS" = "false" ]; then
            echo "Creating secret scope: $SECRET_SCOPE"
            api POST "/api/2.0/secrets/scopes/create" -d "{\"scope\":\"$SECRET_SCOPE\"}"
          else
            echo "Secret scope $SECRET_SCOPE exists"
          fi

          # Helper to put a secret if non-empty
          put_secret() {
            local key="$1" val="$2"
            if [ -n "$val" ]; then
              echo "Setting secret $key in scope $SECRET_SCOPE"
              api POST "/api/2.0/secrets/put" -d "{\"scope\":\"$SECRET_SCOPE\",\"key\":\"$key\",\"string_value\":\"$val\"}"
            else
              echo "Skipping secret $key (empty)"
            fi
          }

          # Populate secrets from GitHub secrets if present
          # Note: Neo4j credentials use '-dev' suffix to support multiple environments,
          # while Aura credentials are shared across environments
          put_secret neo4j-uri-dev "${{ secrets.NEO4J_URI }}"
          put_secret neo4j-username-dev "${{ secrets.NEO4J_USERNAME }}"
          put_secret neo4j-password-dev "${{ secrets.NEO4J_PASSWORD }}"
          put_secret aura-client-id "${{ secrets.AURA_CLIENT_ID }}"
          put_secret aura-client-secret "${{ secrets.AURA_CLIENT_SECRET }}"

      - name: Ensure Terraform remote backend resources exist
        run: |
          set -euo pipefail
          RG="rg-terraform-state"
          SUB_NAME=$(az account show --query name -o tsv | tr '[:upper:]' '[:lower:]' | tr -d '-')
          BASE="tfst"
          SA="${BASE}${SUB_NAME}"  # e.g., tfstfieldengcsaemea
          CONTAINER="tfstate"
          LOCATION="uksouth"

          echo "Ensuring remote backend in RG=$RG SA=$SA CONTAINER=$CONTAINER LOCATION=$LOCATION"
          echo "BACKEND_STORAGE_ACCOUNT=$SA" >> "$GITHUB_ENV"

          # Create Resource Group if missing
          if ! az group show --name "$RG" >/dev/null 2>&1; then
            echo "Creating resource group $RG in $LOCATION"
            az group create --name "$RG" --location "$LOCATION" >/dev/null
          else
            echo "Resource group $RG exists"
          fi

          # Create Storage Account if missing
          if ! az storage account show --name "$SA" --resource-group "$RG" >/dev/null 2>&1; then
            echo "Creating storage account $SA"
            az storage account create \
              --name "$SA" \
              --resource-group "$RG" \
              --location "$LOCATION" \
              --sku Standard_LRS \
              --kind StorageV2 \
              --hns true >/dev/null
          else
            echo "Storage account $SA exists"
          fi

          # Create container if missing (auth via Azure CLI login)
          if ! az storage container show --name "$CONTAINER" --account-name "$SA" --auth-mode login >/dev/null 2>&1; then
            echo "Creating container $CONTAINER"
            az storage container create --name "$CONTAINER" --account-name "$SA" --auth-mode login >/dev/null
          else
            echo "Container $CONTAINER exists"
          fi
          
      - name: Break stale Terraform state lease (best effort)
        run: |
          set -euo pipefail
          SA="${BACKEND_STORAGE_ACCOUNT}"
          CONTAINER="tfstate"
          BLOB="neo4j-databricks-dev.tfstate"
          echo "Attempting best-effort lease break on $CONTAINER/$BLOB in $SA"
          az storage blob lease break \
            --account-name "$SA" \
            --container-name "$CONTAINER" \
            --blob-name "$BLOB" \
            --auth-mode login || true

      - name: Determine var-file
        id: varfile
        working-directory: terraform
        run: |
          if [ -f "terraform.tfvars" ]; then
            echo "file=terraform.tfvars" >> $GITHUB_OUTPUT
          elif [ -f "terraform.tfvars.example" ]; then
            echo "file=terraform.tfvars.example" >> $GITHUB_OUTPUT
          else
            echo "file=" >> $GITHUB_OUTPUT
          fi
            
      - name: Terraform Init
        working-directory: terraform
        run: |
          terraform init \
            -input=false \
            -backend-config="resource_group_name=rg-terraform-state" \
            -backend-config="storage_account_name=${BACKEND_STORAGE_ACCOUNT}" \
            -backend-config="container_name=tfstate" \
            -backend-config="key=${{ github.ref_name == 'main' && 'neo4j-databricks-dev.tfstate' || format('neo4j-databricks-{0}.tfstate', github.ref_name) }}"

      - name: Terraform Plan
        working-directory: terraform
        env:
          TF_VAR_databricks_host: ${{ secrets.DATABRICKS_HOST }}
          TF_VAR_databricks_token: ${{ secrets.DATABRICKS_TOKEN }}
          TF_VAR_aura_client_id: ${{ secrets.AURA_CLIENT_ID }}
          TF_VAR_aura_client_secret: ${{ secrets.AURA_CLIENT_SECRET }}
          DATABRICKS_AUTH_TYPE: pat
        run: |
          VARFILE="${{ steps.varfile.outputs.file }}"
          if [ -n "$VARFILE" ]; then
            terraform plan -input=false -lock-timeout=5m -var-file="$VARFILE" -out=tfplan
          else
            terraform plan -input=false -lock-timeout=5m -out=tfplan
          fi

      - name: Terraform Apply
        working-directory: terraform
        env:
          TF_VAR_databricks_host: ${{ secrets.DATABRICKS_HOST }}
          TF_VAR_databricks_token: ${{ secrets.DATABRICKS_TOKEN }}
          TF_VAR_aura_client_id: ${{ secrets.AURA_CLIENT_ID }}
          TF_VAR_aura_client_secret: ${{ secrets.AURA_CLIENT_SECRET }}
          DATABRICKS_AUTH_TYPE: pat
        run: |
          terraform apply -input=false -auto-approve -lock-timeout=5m tfplan

      - name: Export Terraform Outputs
        working-directory: terraform
        run: |
          terraform output -json > /tmp/terraform-outputs.json
          echo "RESOURCE_GROUP=$(terraform output -raw resource_group_name)" >> $GITHUB_ENV
          echo "STORAGE_ACCOUNT=$(terraform output -raw storage_account_name)" >> $GITHUB_ENV
          echo "DATABRICKS_WORKSPACE_URL=$(terraform output -raw databricks_workspace_url)" >> $GITHUB_ENV

      - name: Upload Storage Sample Data
        run: |
          echo "Uploading sample e-commerce data to Azure Storage..."
          az storage blob upload-batch \
            --account-name ${{ env.BACKEND_STORAGE_ACCOUNT }} \
            --destination pipeline-data/sample-data \
            --source sample-data/ \
            --overwrite

      - name: Provisioning Summary
        working-directory: terraform
        run: |
          echo "=================================="
          echo "Provisioning Complete"
          echo "=================================="
          echo ""
          echo "Environment: $(terraform output -raw environment 2>/dev/null || echo 'dev')"
          echo "Resource Group: $(terraform output -raw resource_group_name 2>/dev/null || echo 'N/A')"
          echo "Databricks Workspace: $(terraform output -raw databricks_workspace_url 2>/dev/null || echo 'N/A')"
          echo "Neo4j Instance: $(terraform output -raw neo4j_instance_id 2>/dev/null || echo 'N/A')"
          echo ""
          echo "âœ… Azure + Databricks + Aura + Unity Catalog provisioned"
