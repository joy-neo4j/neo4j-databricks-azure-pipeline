name: 02 - Provision (Azure + Databricks + Aura + UC)

on:
  workflow_dispatch:

permissions:
  contents: read
  id-token: write

concurrency:
  group: provision-${{ github.ref }}
  cancel-in-progress: true

jobs:
  provision:
    name: Provision single environment via Terraform
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Ensure Terraform remote backend resources exist
        run: |
          set -euo pipefail
          RG="rg-terraform-state"
          SUB_NAME=$(az account show --query name -o tsv | tr '[:upper:]' '[:lower:]' | tr -d '-')
          BASE="tfstate"
          SA="${BASE}${SUB_NAME}"  # e.g., tfstatefieldengcsaemea
          CONTAINER="tfstate"
          LOCATION="uksouth"

          echo "Ensuring remote backend in RG=$RG SA=$SA CONTAINER=$CONTAINER LOCATION=$LOCATION"
          echo "BACKEND_STORAGE_ACCOUNT=$SA" >> "$GITHUB_ENV"

          # Create Resource Group if missing
          if ! az group show --name "$RG" >/dev/null 2>&1; then
            echo "Creating resource group $RG in $LOCATION"
            az group create --name "$RG" --location "$LOCATION" >/dev/null
          else
            echo "Resource group $RG exists"
          fi

          # Create Storage Account if missing
          if ! az storage account show --name "$SA" --resource-group "$RG" >/dev/null 2>&1; then
            echo "Creating storage account $SA"
            az storage account create \
              --name "$SA" \
              --resource-group "$RG" \
              --location "$LOCATION" \
              --sku Standard_LRS \
              --kind StorageV2 \
              --hns true >/dev/null
          else
            echo "Storage account $SA exists"
          fi

          # Create container if missing (auth via Azure CLI login)
          if ! az storage container show --name "$CONTAINER" --account-name "$SA" --auth-mode login >/dev/null 2>&1; then
            echo "Creating container $CONTAINER"
            az storage container create --name "$CONTAINER" --account-name "$SA" --auth-mode login >/dev/null
          else
            echo "Container $CONTAINER exists"
          fi

      - name: Configure Terraform Backend
        working-directory: terraform
        run: |
          cat > backend.tf << EOF
          terraform {
            backend "azurerm" {
              resource_group_name  = "rg-terraform-state"
              storage_account_name = "${BACKEND_STORAGE_ACCOUNT}"
              container_name       = "tfstate"
              key                  = "neo4j-databricks-dev.tfstate"
            }
          }
          EOF

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Determine var-file
        id: varfile
        working-directory: terraform
        run: |
          if [ -f "terraform.tfvars" ]; then
            echo "file=terraform.tfvars" >> $GITHUB_OUTPUT
          elif [ -f "terraform.tfvars.example" ]; then
            echo "file=terraform.tfvars.example" >> $GITHUB_OUTPUT
          else
            echo "file=" >> $GITHUB_OUTPUT
          fi

      - name: Terraform Init
        working-directory: terraform
        run: terraform init

      - name: Terraform Plan
        working-directory: terraform
        env:
          TF_VAR_databricks_host: ${{ secrets.DATABRICKS_HOST }}
          TF_VAR_databricks_token: ${{ secrets.DATABRICKS_TOKEN }}
          TF_VAR_aura_client_id: ${{ secrets.AURA_CLIENT_ID }}
          TF_VAR_aura_client_secret: ${{ secrets.AURA_CLIENT_SECRET }}
        run: |
          VARFILE="${{ steps.varfile.outputs.file }}"
          if [ -n "$VARFILE" ]; then
            terraform plan -var-file="$VARFILE" -out=tfplan
          else
            terraform plan -out=tfplan
          fi

      - name: Terraform Apply
        working-directory: terraform
        env:
          TF_VAR_databricks_host: ${{ secrets.DATABRICKS_HOST }}
          TF_VAR_databricks_token: ${{ secrets.DATABRICKS_TOKEN }}
          TF_VAR_aura_client_id: ${{ secrets.AURA_CLIENT_ID }}
          TF_VAR_aura_client_secret: ${{ secrets.AURA_CLIENT_SECRET }}
        run: |
          VARFILE="${{ steps.varfile.outputs.file }}"
          if [ -n "$VARFILE" ]; then
            terraform apply -auto-approve -var-file="$VARFILE" tfplan
          else
            terraform apply -auto-approve tfplan
          fi

      - name: Upload Storage Sample Data
        run: |
          echo "Uploading sample e-commerce data to Azure Storage..."
          az storage blob upload-batch \
            --account-name ${{ env.BACKEND_STORAGE_ACCOUNT }} \
            --destination pipeline-data/sample-data \
            --source sample-data/ \
            --overwrite

      - name: Provisioning Summary
        working-directory: terraform
        run: |
          echo "=================================="
          echo "Provisioning Complete"
          echo "=================================="
          echo ""
          echo "Environment: $(terraform output -raw environment 2>/dev/null || echo 'dev')"
          echo "Resource Group: $(terraform output -raw resource_group_name 2>/dev/null || echo 'N/A')"
          echo "Databricks Workspace: $(terraform output -raw databricks_workspace_url 2>/dev/null || echo 'N/A')"
          echo "Neo4j Instance: $(terraform output -raw neo4j_instance_id 2>/dev/null || echo 'N/A')"
          echo ""
          echo "âœ… Azure + Databricks + Aura + Unity Catalog provisioned"
