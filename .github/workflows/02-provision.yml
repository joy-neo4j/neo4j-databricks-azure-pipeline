name: 02 - Provision (Azure + Databricks + Aura + UC)

on:
  workflow_dispatch:

permissions:
  contents: read
  id-token: write

concurrency:
  group: provision-${{ github.ref }}
  cancel-in-progress: true

jobs:
  provision:
    name: Provision single environment via Terraform
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Ensure Terraform remote backend resources exist
        run: |
          set -euo pipefail
          RG="rg-terraform-state"
          SUB_NAME=$(az account show --query name -o tsv | tr '[:upper:]' '[:lower:]' | tr -d '-')
          BASE="tfst"
          SA="${BASE}${SUB_NAME}"  # e.g., tfstfieldengcsaemea
          CONTAINER="tfstate"
          LOCATION="uksouth"

          echo "Ensuring remote backend in RG=$RG SA=$SA CONTAINER=$CONTAINER LOCATION=$LOCATION"
          echo "BACKEND_STORAGE_ACCOUNT=$SA" >> "$GITHUB_ENV"

          # Create Resource Group if missing
          if ! az group show --name "$RG" >/dev/null 2>&1; then
            echo "Creating resource group $RG in $LOCATION"
            az group create --name "$RG" --location "$LOCATION" >/dev/null
          else
            echo "Resource group $RG exists"
          fi

          # Create Storage Account if missing
          if ! az storage account show --name "$SA" --resource-group "$RG" >/dev/null 2>&1; then
            echo "Creating storage account $SA"
            az storage account create \
              --name "$SA" \
              --resource-group "$RG" \
              --location "$LOCATION" \
              --sku Standard_LRS \
              --kind StorageV2 \
              --hns true >/dev/null
          else
            echo "Storage account $SA exists"
          fi

          # Create container if missing (auth via Azure CLI login)
          if ! az storage container show --name "$CONTAINER" --account-name "$SA" --auth-mode login >/dev/null 2>&1; then
            echo "Creating container $CONTAINER"
            az storage container create --name "$CONTAINER" --account-name "$SA" --auth-mode login >/dev/null
          else
            echo "Container $CONTAINER exists"
          fi

      - name: Terraform Init
        working-directory: terraform
        run: |
          terraform init \
            -input=false \
            -backend-config="resource_group_name=rg-terraform-state" \
            -backend-config="storage_account_name=${BACKEND_STORAGE_ACCOUNT}" \
            -backend-config="container_name=tfstate" \
            -backend-config="key=neo4j-databricks-dev.tfstate"

      - name: Terraform Plan
        working-directory: terraform
        env:
          TF_VAR_databricks_host: ${{ secrets.DATABRICKS_HOST }}
          TF_VAR_databricks_token: ${{ secrets.DATABRICKS_TOKEN }}
          TF_VAR_aura_client_id: ${{ secrets.AURA_CLIENT_ID }}
          TF_VAR_aura_client_secret: ${{ secrets.AURA_CLIENT_SECRET }}
        run: |
          terraform plan -out=tfplan

      - name: Terraform Apply
        working-directory: terraform
        env:
          TF_VAR_databricks_host: ${{ secrets.DATABRICKS_HOST }}
          TF_VAR_databricks_token: ${{ secrets.DATABRICKS_TOKEN }}
          TF_VAR_aura_client_id: ${{ secrets.AURA_CLIENT_ID }}
          TF_VAR_aura_client_secret: ${{ secrets.AURA_CLIENT_SECRET }}
        run: |
            terraform apply -auto-approve tfplan

      - name: Export Terraform Outputs
        working-directory: terraform
        run: |
          terraform output -json > /tmp/terraform-outputs.json
          echo "RESOURCE_GROUP=$(terraform output -raw resource_group_name)" >> $GITHUB_ENV
          echo "STORAGE_ACCOUNT=$(terraform output -raw storage_account_name)" >> $GITHUB_ENV
          echo "DATABRICKS_WORKSPACE_URL=$(terraform output -raw databricks_workspace_url)" >> $GITHUB_ENV

      - name: Upload Storage Sample Data
        run: |
          echo "Uploading sample e-commerce data to Azure Storage..."
          az storage blob upload-batch \
            --account-name ${{ env.BACKEND_STORAGE_ACCOUNT }} \
            --destination pipeline-data/sample-data \
            --source sample-data/ \
            --overwrite

      - name: Provisioning Summary
        working-directory: terraform
        run: |
          echo "=================================="
          echo "Provisioning Complete"
          echo "=================================="
          echo ""
          echo "Environment: $(terraform output -raw environment 2>/dev/null || echo 'dev')"
          echo "Resource Group: $(terraform output -raw resource_group_name 2>/dev/null || echo 'N/A')"
          echo "Databricks Workspace: $(terraform output -raw databricks_workspace_url 2>/dev/null || echo 'N/A')"
          echo "Neo4j Instance: $(terraform output -raw neo4j_instance_id 2>/dev/null || echo 'N/A')"
          echo ""
          echo "âœ… Azure + Databricks + Aura + Unity Catalog provisioned"
