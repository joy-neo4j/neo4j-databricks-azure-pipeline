name: Scheduled ETL Pipeline

on:
  workflow_dispatch:

permissions:
  contents: read

jobs:
  validate-secrets:
    name: Validate Required Secrets
    runs-on: ubuntu-latest
    steps:
      - name: Check Databricks and Neo4j secrets
        shell: bash
        run: |
          missing=0
          host="${{ secrets.DATABRICKS_HOST }}"
          token="${{ secrets.DATABRICKS_TOKEN }}"
          if [ -z "$host" ]; then echo "::error::Missing secret: DATABRICKS_HOST"; missing=1; fi
          if [ -z "$token" ]; then echo "::error::Missing secret: DATABRICKS_TOKEN"; missing=1; fi
          if [ -z "${{ secrets.NEO4J_URI }}" ]; then echo "::error::Missing secret: NEO4J_URI"; missing=1; fi
          if [ -z "${{ secrets.NEO4J_USER }}" ]; then echo "::error::Missing secret: NEO4J_USER"; missing=1; fi
          if [ -z "${{ secrets.NEO4J_PASSWORD }}" ]; then echo "::error::Missing secret: NEO4J_PASSWORD"; missing=1; fi
          if [ $missing -ne 0 ]; then echo "Secrets missing"; exit 1; fi
  run-etl:
    name: Run ETL Pipeline
    runs-on: ubuntu-latest
    environment: dev
    needs: validate-secrets
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install databricks-cli databricks-sdk requests

      - name: Configure Databricks
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          mkdir -p ~/.databrickscfg
          cat > ~/.databrickscfg << EOF
          [DEFAULT]
          host = $DATABRICKS_HOST
          token = $DATABRICKS_TOKEN
          EOF

      - name: Trigger ETL job
        id: trigger_job
        run: |
          chmod +x scripts/run-etl-pipeline.sh
          ./scripts/run-etl-pipeline.sh dev

      - name: Monitor job execution
        run: |
          echo "âœ… ETL pipeline triggered successfully"
          echo "Check job status in Databricks workspace"

      - name: Report metrics
        if: always()
        run: |
          echo "## ETL Pipeline Execution" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** dev" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered at:** $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY

  notify-on-failure:
    name: Notify on Failure
    runs-on: ubuntu-latest
    needs: run-etl
    if: failure()
    steps:
      - name: Send Slack notification
        if: ${{ secrets.SLACK_WEBHOOK_URL != '' }}
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          text: 'ETL Pipeline failed in dev environment'
          webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Send email notification
        if: ${{ secrets.NOTIFICATION_EMAIL != '' }}
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: ETL Pipeline Failure Alert
          to: ${{ secrets.NOTIFICATION_EMAIL }}
          from: GitHub Actions
          body: |
            The scheduled ETL pipeline has failed in dev environment.
            
            Please check the GitHub Actions logs for details:
            ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
