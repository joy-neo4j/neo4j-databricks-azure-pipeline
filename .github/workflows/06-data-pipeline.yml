name: 06 - Data Pipeline

on:
  workflow_dispatch:

permissions:
  contents: read
  id-token: write

concurrency:
  group: data-pipeline-${{ github.ref }}
  cancel-in-progress: true

jobs:
  validate-secrets:
    name: Validate Databricks Secrets
    runs-on: ubuntu-latest
    steps:
      - name: Check DATABRICKS_HOST/TOKEN
        shell: bash
        run: |
          if [ -z "${{ secrets.DATABRICKS_HOST }}" ] || [ -z "${{ secrets.DATABRICKS_TOKEN }}" ]; then
            echo "::error::Missing DATABRICKS_HOST or DATABRICKS_TOKEN"; exit 1; fi

  validate-notebooks:
    name: Validate Notebooks Syntax
    runs-on: ubuntu-latest
    needs: validate-secrets
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install pyspark neo4j pytest

      - name: Syntax check notebooks
        run: |
          for notebook in databricks/notebooks/*.py; do
            echo "Checking $notebook"
            python -m py_compile "$notebook"
          done
          echo "✅ All notebooks passed syntax check"

      - name: Pipeline Validation Summary
        run: |
          echo "=================================="
          echo "Data Pipeline Validation Complete"
          echo "=================================="
          echo ""
          echo "Notebooks Validated:"
          echo "  ✅ CSV Ingestion"
          echo "  ✅ Data Validation"
          echo "  ✅ Graph Transformation"
          echo "  ✅ Neo4j Loading"
          echo "  ✅ Customer 360 Analytics"
          echo "  ✅ Product Recommendations"
          echo ""
          echo "Note: Notebooks and jobs are deployed via Terraform (02-provision workflow)"
          echo "This workflow only validates notebook syntax."
