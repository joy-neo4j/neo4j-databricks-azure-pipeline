name: Deploy Data Pipeline

on:
  workflow_dispatch:

concurrency:
  group: deploy-data-pipeline-${{ github.ref }}-dev
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  validate-secrets:
    name: Validate Required Secrets
    runs-on: ubuntu-latest
    steps:
      - name: Check environment-scoped or default secrets
        shell: bash
        run: |
          missing=0
          # Prefer environment-scoped secrets like DEV_DATABRICKS_HOST, fallback to default
          host="${{ secrets.DATABRICKS_HOST }}"
          token="${{ secrets.DATABRICKS_TOKEN }}"
          if [ -z "$host" ]; then echo "::error::Missing secret: DATABRICKS_HOST (or env-scoped)"; missing=1; fi
          if [ -z "$token" ]; then echo "::error::Missing secret: DATABRICKS_TOKEN (or env-scoped)"; missing=1; fi
          if [ $missing -ne 0 ]; then echo "Secrets missing"; exit 1; fi

  deploy-notebooks:
    name: Deploy Databricks Notebooks
    runs-on: ubuntu-latest
    environment: dev
    needs: validate-secrets
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Databricks CLI
        run: pip install databricks-cli databricks-sdk

      - name: Configure Databricks
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
        run: |
          mkdir -p ~/.databrickscfg
          cat > ~/.databrickscfg << EOF
          [DEFAULT]
          host = $DATABRICKS_HOST
          token = $DATABRICKS_TOKEN
          EOF

      - name: Upload notebooks
        run: |
          databricks workspace import_dir databricks/notebooks /Shared/neo4j-pipeline --overwrite
          echo "✅ Notebooks uploaded successfully"

      - name: Update job configurations
        run: |
          chmod +x scripts/create-databricks-jobs.sh
          ./scripts/create-databricks-jobs.sh dev

  validate-notebooks:
    name: Validate Notebooks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          pip install pyspark neo4j pytest

      - name: Syntax check notebooks
        run: |
          for notebook in databricks/notebooks/*.py; do
            echo "Checking $notebook"
            python -m py_compile "$notebook"
          done
          echo "✅ All notebooks passed syntax check"
